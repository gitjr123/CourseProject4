{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __1) Feature extraction__ \n",
    "In this first part of the project, start by extracting a set of high-level features for each\n",
    "image in the data set. To achieve this, you can use ex. the Inception v3 or MobileNet v2\n",
    "ConvNets which respectively extract 2048 and 1280 high-level features.\n",
    "This high-level features should then be used for all of the tasks in this project, except for\n",
    "when it is stated otherwise. In other words, the PCA exploration and all models (except\n",
    "for the Convolutional Neural Network) should use these high-level features. And in the\n",
    "case where we ask you to visualize the images, we of course mean to visualize the raw\n",
    "images with their pixel values.\n",
    "Suggestion: consider storing the extracted high-level features, e.g. in npz files, for\n",
    "quickly reloading them into each of the following notebooks.\n",
    "\n",
    "__Note:__ All your models should be trained on the training set, and the 􀁿ne tuning of your\n",
    "hyperparameters should be validated on the validation set. The 􀁿nal test set should only\n",
    "be used for the final comparison to test the accuracies of your models on a new dataset.\n",
    "\n",
    "However, in the case where you use a cross-validation approach, you can of course\n",
    "merge the train and validation set into one bigger dataset and use this for model fitting.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bL54LWCHt5q5"
   },
   "source": [
    "#### Get libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.0.0\n",
      "Hub version: 0.9.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy            as np\n",
    "import tensorflow       as tf\n",
    "import tensorflow_hub   as hub\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Import Keras API from tensorflow\n",
    "from tensorflow.keras        import layers, models\n",
    "from tensorflow.keras        import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Test the version of tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmaHHH7Pvmth"
   },
   "source": [
    "#### Configuring inception_v3 module to use\n",
    "Hint from https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4: \n",
    "Inception V3 is a neural network architecture for image classification.\n",
    "This TF-Hub module uses the TF-Slim implementation of inception_v3. \n",
    "The module contains a trained instance of the network, packaged to get feature vectors from images. \n",
    "If you want the full model including the classification it was originally trained for, use module google/imagenet/inception_v3/classification/1 instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlsEcKVeuCnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4 with input size (299, 299)\n"
     ]
    }
   ],
   "source": [
    "handle_base, pixels = (\"inception_v3\" # module selection\n",
    "                      , 299) # number of pixels )\n",
    "MODULE_HANDLE       = \"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
    "IMAGE_SIZE          = (299, 299)\n",
    "\n",
    "print(\"Using {} with input size {}\".format(MODULE_HANDLE, (299,299)))\n",
    "\n",
    "data_dir = 'C:/Users/tgdreju4/OneDrive - Swisscom/EPFL/Notebooks/04ML/swissroads/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaJW3XrPyFiF"
   },
   "outputs": [],
   "source": [
    "do_fine_tuning       = False #@param {type:\"boolean\"}\n",
    "do_data_augmentation = True #@param {type:\"boolean\"}\n",
    "BATCH_SIZE           = 10 #@param {type:\"integer\"}\n",
    "epochs               = 5\n",
    "#modelname            = handle_base+'_FT_'+str(do_fine_tuning)+'_DA_'+str(do_data_augmentation)+'_BS_'+str(BATCH_SIZE)+'_Ep_'+str(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FS_gVStowW3G"
   },
   "source": [
    "#### Model definition and extract high level features\n",
    "\n",
    "This model will extract 2048 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import      os\n",
    "proxy       = 'https://clientproxy.corproot.net:8079'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and build the keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50FYNIb1dmJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     multiple                  21802784  \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),])\n",
    "\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ImageDataGenerator\n",
    "\n",
    "Get input from here: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html plus discussion with my Swisscom colleague Mario Useche\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing and data augmentation\n",
    "In order to make the most of our few training examples, we will \"augment\" them via a number of random transformations, so that our model would never see twice the exact same picture. This helps prevent overfitting and helps the model generalize better.\n",
    "In Keras this can be done via the keras.preprocessing.image.ImageDataGenerator class. This class allows you to:\n",
    "configure random transformations and normalization operations to be done on your image data during training\n",
    "instantiate generators of augmented image batches (and their labels) via .flow(data, labels) or .flow_from_directory(directory). These generators can then be used with the Keras model methods that accept data generators as inputs, fit_generator, evaluate_generator and predict_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataflow_kwargs = dict(\n",
    "                        directory=data_dir+'train',\n",
    "                        shuffle=False, \n",
    "                        target_size=IMAGE_SIZE,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        interpolation='bilinear')\n",
    "test_dataflow_kwargs = dict(\n",
    "                        directory=data_dir+'test',\n",
    "                        shuffle=False, \n",
    "                        target_size=IMAGE_SIZE,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        interpolation='bilinear')\n",
    "valid_dataflow_kwargs = dict(\n",
    "                        directory=data_dir+'valid',\n",
    "                        shuffle=False, \n",
    "                        target_size=IMAGE_SIZE,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        interpolation='bilinear')\n",
    "\n",
    "\n",
    "\n",
    "# Data Augmentation will be used in future tasks\n",
    "if do_data_augmentation:\n",
    "    train_datagen_kwargs  = dict(\n",
    "                       rescale=1./255,\n",
    "                       rotation_range=40,\n",
    "                       horizontal_flip=True,\n",
    "                       width_shift_range=0.2, \n",
    "                       height_shift_range=0.2,\n",
    "                       shear_range=0.2,\n",
    "                       zoom_range=0.2)\n",
    "else :                 train_datagen_kwargs = dict(rescale=1./255)  \n",
    "    \n",
    "valid_datagen_kwargs =  dict(rescale=1./255)\n",
    "test_datagen_kwargs  =  dict(rescale=1./255)\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umB5tswsfTEQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen   = tf.keras.preprocessing.image.ImageDataGenerator(**train_datagen_kwargs)\n",
    "train_generator = train_datagen.flow_from_directory(**train_dataflow_kwargs)\n",
    "\n",
    "valid_datagen   = tf.keras.preprocessing.image.ImageDataGenerator(**valid_datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(**valid_dataflow_kwargs)\n",
    "\n",
    "test_datagen   = tf.keras.preprocessing.image.ImageDataGenerator(**test_datagen_kwargs)\n",
    "test_generator = test_datagen.flow_from_directory(**test_dataflow_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Features for the Train, Test and Validation Datasets\n",
    "  \n",
    "For each Image generator, extract the features and numpy arrays and save them in a npz file with it's corresponding category(label) and filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.npz  features with shape (280, 2048)\n",
      "train.npz  labels with shape (280,)\n",
      "train.npz  files with shape (280,)\n",
      "test.npz  features with shape (50, 2048)\n",
      "test.npz  labels with shape (50,)\n",
      "test.npz  files with shape (50,)\n",
      "valid.npz  features with shape (139, 2048)\n",
      "valid.npz  labels with shape (139,)\n",
      "valid.npz  files with shape (139,)\n"
     ]
    }
   ],
   "source": [
    "file=data_dir+'train.npz'\n",
    "np.savez(file,features=model.predict(train_generator), labels=train_generator.labels ,files=train_generator.filenames)\n",
    "with np.load(file, allow_pickle=False) as npz_file:\n",
    "    for arr in list(npz_file.keys()):\n",
    "        print('train.npz  '+arr +' with shape '+str(npz_file[arr].shape))\n",
    "        \n",
    "file=data_dir+'test.npz'\n",
    "np.savez(file,features=model.predict(test_generator), labels=test_generator.labels ,files=test_generator.filenames)\n",
    "with np.load(file, allow_pickle=False) as npz_file:\n",
    "    for arr in list(npz_file.keys()):\n",
    "        print('test.npz  '+arr +' with shape '+str(npz_file[arr].shape))\n",
    "              \n",
    "file=data_dir+'valid.npz'\n",
    "np.savez(file,features=model.predict(valid_generator), labels=valid_generator.labels ,files=valid_generator.filenames)\n",
    "with np.load(file, allow_pickle=False) as npz_file:\n",
    "    for arr in list(npz_file.keys()):\n",
    "        print('valid.npz  '+arr +' with shape '+str(npz_file[arr].shape)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
